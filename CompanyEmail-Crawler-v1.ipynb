{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niranjan/MY-WORLD/DataScience/Code-Repository/Company-Email-Crawler\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompanyEmail-Crawler-v1.ipynb  niki-Email.csv  README.md  tesla-Email.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.linkextractors.lxmlhtml import LxmlLinkExtractor\n",
    "from googlesearch import search\n",
    "logging.getLogger('scrapy').propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(tag, n, language):\n",
    "    # This functions gets the search string urls from the google\n",
    "    urls = [url for url in search(tag, stop=n, lang=language)][:n]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailSpider(scrapy.Spider):\n",
    "    \n",
    "    name = 'email'\n",
    "    \n",
    "    #Inheriting the scrapy.Scider properties into MailSpider\n",
    "    #Spiders are custom classes written by Scrapy users to parse responses and extract items (aka scraped items)\n",
    "    #from them or additional URLs (requests) to follow. Each spider is able to handle a specific domain\n",
    "    #(or group of domains)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        links = LxmlLinkExtractor(allow=()).extract_links(response)\n",
    "        links = [str(link.url) for link in links]\n",
    "        links.append(str(response.url))\n",
    "        \n",
    "        for link in links:\n",
    "            yield scrapy.Request(url=link, callback=self.parse_link) \n",
    "            \n",
    "    def parse_link(self, response):\n",
    "        \n",
    "        for word in self.reject:\n",
    "            if word in str(response.url):\n",
    "                return\n",
    "            \n",
    "        html_text = str(response.text)\n",
    "        mail_list = re.findall(r'\\w+@\\w+\\.{1}\\w+', html_text)\n",
    "    \n",
    "\n",
    "        dic = {'email': mail_list, 'link': str(response.url)}\n",
    "        df = pd.DataFrame(dic)\n",
    "        \n",
    "        df.to_csv(self.path, mode='a', header=False)\n",
    "        df.to_csv(self.path, mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user(question):\n",
    "    response = input(question + ' y/n' + '\\n')\n",
    "    if response == 'y':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def create_file(path):\n",
    "    response = False\n",
    "    if os.path.exists(path):\n",
    "        response = ask_user('File already exists, replace?')\n",
    "        if response == False: return \n",
    "    \n",
    "    with open(path, 'wb') as file: \n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(tag, n, language, path, reject=[]):\n",
    "    \n",
    "    create_file(path)\n",
    "    df = pd.DataFrame(columns=['email', 'link'], index=[0])\n",
    "    df.to_csv(path, mode='w', header=True)\n",
    "    \n",
    "    print('Collecting Google urls...')\n",
    "    google_urls = get_urls(tag, n, language)\n",
    "    \n",
    "    print('Searching for emails...')\n",
    "    process = CrawlerProcess({'USER_AGENT': 'Mozilla/5.0'})\n",
    "    process.crawl(MailSpider, start_urls=google_urls, path=path, reject=reject)\n",
    "    process.start()\n",
    "    \n",
    "    print('Cleaning emails...')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df.columns = ['email', 'link']\n",
    "    df = df.drop_duplicates(subset='email')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(path, mode='w', header=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter companey name:tesla\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://electrek.co/2020/01/23/tesla-official-loopholes-stupid-laws-to-sale-michigan/?sa=X&ved=2ahUKEwi2iJOppJvnAhUXxzgGHZJmCKkQqOcBMAB6BAgBEAI']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cname = str(input('Enter companey name:'))\n",
    "get_urls(cname,1,'en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Google urls...\n",
      "Searching for emails...\n",
      "Cleaning emails...\n"
     ]
    }
   ],
   "source": [
    "bad_words = ['facebook', 'instagram', 'youtube', 'twitter', 'wiki']\n",
    "df = get_info(cname, 1, 'pt', cname+'-Email.csv', reject=bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>portrait@2.jpg</td>\n",
       "      <td>https://www.tesla.com/roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hero@2.jpg</td>\n",
       "      <td>https://www.tesla.com/roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobile@2.jpg</td>\n",
       "      <td>https://www.tesla.com/roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model3_top_view@2x.jpg</td>\n",
       "      <td>https://www.tesla.com/model3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    email                            link\n",
       "0                     NaN                             NaN\n",
       "1          portrait@2.jpg  https://www.tesla.com/roadster\n",
       "2              hero@2.jpg  https://www.tesla.com/roadster\n",
       "3            mobile@2.jpg  https://www.tesla.com/roadster\n",
       "4  model3_top_view@2x.jpg    https://www.tesla.com/model3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13                                 forums@tesla.com\n",
       "18                                  press@tesla.com\n",
       "19                                  Press@tesla.com\n",
       "20                                eupress@tesla.com\n",
       "21                                EUPress@tesla.com\n",
       "22                              apacpress@tesla.com\n",
       "23                              APACPress@tesla.com\n",
       "24                                    DPO@tesla.com\n",
       "25                                privacy@tesla.com\n",
       "26                          ServiceHelpNA@tesla.com\n",
       "27                   charginginstallation@tesla.com\n",
       "28                            resolutions@tesla.com\n",
       "29                                  legal@tesla.com\n",
       "30    c2ba986ebc5a4649aa605dd8b7e942c2@errlog.tesla\n",
       "39                             southkorea@tesla.com\n",
       "41                   accommodationrequest@tesla.com\n",
       "55                           tesla_community@2x.jpg\n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df = df[df['email'].str.contains(cname, na=False)]['email']\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"email\",\"index\":[13,18,19,20,21,22,23,24,25,26,27,28,29,30,39,41,55],\"data\":[\"forums@tesla.com\",\"press@tesla.com\",\"Press@tesla.com\",\"eupress@tesla.com\",\"EUPress@tesla.com\",\"apacpress@tesla.com\",\"APACPress@tesla.com\",\"DPO@tesla.com\",\"privacy@tesla.com\",\"ServiceHelpNA@tesla.com\",\"charginginstallation@tesla.com\",\"resolutions@tesla.com\",\"legal@tesla.com\",\"c2ba986ebc5a4649aa605dd8b7e942c2@errlog.tesla\",\"southkorea@tesla.com\",\"accommodationrequest@tesla.com\",\"tesla_community@2x.jpg\"]}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(lcemail, memail):\n",
    "    #similar function gives the ratio between two strings\n",
    "    return SequenceMatcher(None, lcemail, memail).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forums@tesla.com',\n",
       " 'press@tesla.com',\n",
       " 'Press@tesla.com',\n",
       " 'eupress@tesla.com',\n",
       " 'EUPress@tesla.com',\n",
       " 'apacpress@tesla.com',\n",
       " 'APACPress@tesla.com',\n",
       " 'DPO@tesla.com',\n",
       " 'privacy@tesla.com',\n",
       " 'ServiceHelpNA@tesla.com',\n",
       " 'charginginstallation@tesla.com',\n",
       " 'resolutions@tesla.com',\n",
       " 'legal@tesla.com',\n",
       " 'c2ba986ebc5a4649aa605dd8b7e942c2@errlog.tesla',\n",
       " 'southkorea@tesla.com',\n",
       " 'accommodationrequest@tesla.com',\n",
       " 'tesla_community@2x.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elist = c_df.tolist()\n",
    "len(elist)\n",
    "elist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eupress@tesla.com'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ebucket(Email bucket) has the all companies email format keys words so that we can get better accuracy \n",
    "Ebucket = ['info','support','sales','press','customercare','emeasales','media','contacts']\n",
    "\n",
    "#Dbucket (Domain bucket) has the all the domain name extentions\n",
    "Dbucket = ['.in','.com','.co.in','.org','.io','.ai','co','.app','.net','.int','.edu','.gov','.mil']\n",
    "cemail=[]\n",
    "\n",
    "for em in range(len(elist)):\n",
    "    for eb in range(len(Ebucket)):\n",
    "        for db in range(len(Dbucket)):\n",
    "            if similar(elist[em],Ebucket[eb]+'@'+cname+Dbucket[db]) > .89:\n",
    "                cemail=elist[em]\n",
    "        \n",
    "cemail\n",
    "\n",
    "\n",
    "#The input is 'company name'- output: emailid of the company- this CompanyEmail-Crawler works for almost\n",
    "#all companies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
